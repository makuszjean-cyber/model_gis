{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f8e55f",
   "metadata": {},
   "source": [
    "# D√©tection de palmiers avec YOLOv8 + Export ONNX pour Deepness (QGIS)\n",
    "\n",
    "Ce notebook permet de :\n",
    "1. Monter Google Drive et acc√©der au dataset\n",
    "2. Installer les d√©pendances n√©cessaires\n",
    "3. **Diagnostiquer** le dataset (labels, tailles de bboxes, images)\n",
    "4. Entra√Æner un mod√®le **YOLOv8s** optimis√© sur des images de palmiers\n",
    "5. Exporter le mod√®le au format ONNX\n",
    "6. Ajouter les m√©tadonn√©es Deepness (plugin QGIS) au fichier ONNX\n",
    "7. Sauvegarder le mod√®le final dans Google Drive\n",
    "\n",
    "**Pr√©requis** : le dataset doit √™tre dans Google Drive avec la structure suivante :\n",
    "```\n",
    "dataset_palmiers/\n",
    "‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ val/\n",
    "‚îú‚îÄ‚îÄ labels/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ val/\n",
    "‚îî‚îÄ‚îÄ palms.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca7196",
   "metadata": {},
   "source": [
    "## 1. Monter Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c87f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4ff86",
   "metadata": {},
   "source": [
    "## 2. Installer les d√©pendances\n",
    "\n",
    "On installe `ultralytics` (YOLOv8) et `onnx` (pour manipuler les m√©tadonn√©es du mod√®le export√©)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics onnx --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd05db0",
   "metadata": {},
   "source": [
    "## 3. D√©finir le chemin du dataset et mettre √† jour `palms.yaml`\n",
    "\n",
    "On met √† jour le fichier `palms.yaml` pour que le chemin (`path`) pointe vers le dossier dans Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# --- Trouver automatiquement le dataset dans Google Drive ---\n",
    "DRIVE_ROOT = '/content/drive/MyDrive'\n",
    "\n",
    "# Chemins possibles (ajoutez le v√¥tre si diff√©rent)\n",
    "candidates = [\n",
    "    os.path.join(DRIVE_ROOT, 'Recherche', 'dataset_palmiers'),\n",
    "    os.path.join(DRIVE_ROOT, 'dataset_palmiers'),\n",
    "    os.path.join(DRIVE_ROOT, 'recherche', 'dataset_palmiers'),\n",
    "]\n",
    "\n",
    "DATASET_DIR = None\n",
    "for path in candidates:\n",
    "    if os.path.isdir(path):\n",
    "        DATASET_DIR = path\n",
    "        break\n",
    "\n",
    "# Si aucun candidat trouv√©, afficher le contenu du Drive pour aider\n",
    "if DATASET_DIR is None:\n",
    "    print(\"‚ùå Dataset non trouv√© dans les chemins suivants :\")\n",
    "    for p in candidates:\n",
    "        print(f\"   {p}\")\n",
    "    print(f\"\\nüìÇ Contenu de {DRIVE_ROOT} :\")\n",
    "    for item in sorted(os.listdir(DRIVE_ROOT)):\n",
    "        full = os.path.join(DRIVE_ROOT, item)\n",
    "        marker = 'üìÅ' if os.path.isdir(full) else 'üìÑ'\n",
    "        print(f\"   {marker} {item}\")\n",
    "    # Chercher r√©cursivement un dossier dataset_palmiers\n",
    "    print(\"\\nüîç Recherche de 'dataset_palmiers' dans le Drive...\")\n",
    "    for root, dirs, files in os.walk(DRIVE_ROOT):\n",
    "        if 'dataset_palmiers' in dirs:\n",
    "            found = os.path.join(root, 'dataset_palmiers')\n",
    "            print(f\"   ‚úÖ Trouv√© : {found}\")\n",
    "    raise FileNotFoundError(\"Modifiez DATASET_DIR avec le bon chemin ci-dessus.\")\n",
    "\n",
    "YAML_PATH = os.path.join(DATASET_DIR, 'palms.yaml')\n",
    "assert os.path.isfile(YAML_PATH), f\"Le fichier palms.yaml n'existe pas dans {DATASET_DIR}\"\n",
    "\n",
    "print(f\"‚úÖ Dataset trouv√© : {DATASET_DIR}\")\n",
    "\n",
    "# Mettre √† jour le path dans palms.yaml pour pointer vers Colab\n",
    "with open(YAML_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['path'] = DATASET_DIR\n",
    "\n",
    "with open(YAML_PATH, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"Configuration du dataset :\")\n",
    "print(yaml.dump(config, default_flow_style=False, allow_unicode=True))\n",
    "\n",
    "# V√©rifier la pr√©sence des images et labels\n",
    "for split in ['train', 'val']:\n",
    "    img_dir = os.path.join(DATASET_DIR, 'images', split)\n",
    "    lbl_dir = os.path.join(DATASET_DIR, 'labels', split)\n",
    "    n_img = len([f for f in os.listdir(img_dir) if f.endswith(('.tif', '.tiff', '.png', '.jpg'))])\n",
    "    n_lbl = len([f for f in os.listdir(lbl_dir) if f.endswith('.txt')])\n",
    "    print(f\"  {split}: {n_img} images, {n_lbl} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575626dc",
   "metadata": {},
   "source": [
    "## 4. Diagnostic du dataset\n",
    "\n",
    "Avant d'entra√Æner, on v√©rifie la qualit√© du dataset :\n",
    "- Labels vides ou manquants\n",
    "- Distribution des tailles de bounding boxes\n",
    "- Nombre d'objets par image\n",
    "\n",
    "Cela permet de d√©tecter des probl√®mes en amont (annotations incorrectes, objets trop petits, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e359041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSTIC DU DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_widths, all_heights, objects_per_image = [], [], []\n",
    "empty_labels, missing_labels = [], []\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    img_dir = os.path.join(DATASET_DIR, 'images', split)\n",
    "    lbl_dir = os.path.join(DATASET_DIR, 'labels', split)\n",
    "\n",
    "    images = sorted(glob.glob(os.path.join(img_dir, '*.*')))\n",
    "    print(f\"\\n--- {split.upper()} ---\")\n",
    "    print(f\"  Images trouv√©es : {len(images)}\")\n",
    "\n",
    "    for img_path in images:\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        lbl_path = os.path.join(lbl_dir, base + '.txt')\n",
    "\n",
    "        if not os.path.exists(lbl_path):\n",
    "            missing_labels.append(f\"{split}/{base}\")\n",
    "            objects_per_image.append(0)\n",
    "            continue\n",
    "\n",
    "        with open(lbl_path, 'r') as f:\n",
    "            lines = [l.strip() for l in f.readlines() if l.strip()]\n",
    "\n",
    "        if len(lines) == 0:\n",
    "            empty_labels.append(f\"{split}/{base}\")\n",
    "            objects_per_image.append(0)\n",
    "            continue\n",
    "\n",
    "        objects_per_image.append(len(lines))\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                w, h = float(parts[3]), float(parts[4])\n",
    "                all_widths.append(w)\n",
    "                all_heights.append(h)\n",
    "\n",
    "if missing_labels:\n",
    "    print(f\"\\n‚ö†Ô∏è  Labels MANQUANTS ({len(missing_labels)}) : {missing_labels[:10]}\")\n",
    "if empty_labels:\n",
    "    print(f\"‚ö†Ô∏è  Labels VIDES ({len(empty_labels)}) : {empty_labels[:10]}\")\n",
    "if not missing_labels and not empty_labels:\n",
    "    print(\"\\n‚úÖ Tous les labels sont pr√©sents et non-vides.\")\n",
    "\n",
    "total_objects = sum(objects_per_image)\n",
    "print(f\"\\nüìä Statistiques :\")\n",
    "print(f\"  Total d'objets annot√©s : {total_objects}\")\n",
    "print(f\"  Objets/image ‚Äî min: {min(objects_per_image)}, max: {max(objects_per_image)}, \"\n",
    "      f\"moyenne: {np.mean(objects_per_image):.1f}, m√©diane: {np.median(objects_per_image):.0f}\")\n",
    "\n",
    "# Graphiques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Distribution du nombre d'objets par image\n",
    "axes[0].hist(objects_per_image, bins=30, color='steelblue', edgecolor='white')\n",
    "axes[0].set_title(\"Objets par image\")\n",
    "axes[0].set_xlabel(\"Nombre d'objets\")\n",
    "axes[0].set_ylabel(\"Nombre d'images\")\n",
    "\n",
    "# Distribution des largeurs de bbox (normalis√©es)\n",
    "axes[1].hist(all_widths, bins=50, color='coral', edgecolor='white')\n",
    "axes[1].set_title(\"Largeur des bboxes (normalis√©e)\")\n",
    "axes[1].set_xlabel(\"Largeur\")\n",
    "axes[1].axvline(np.median(all_widths), color='red', linestyle='--', label=f'm√©diane={np.median(all_widths):.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "# Distribution des hauteurs de bbox (normalis√©es)\n",
    "axes[2].hist(all_heights, bins=50, color='mediumseagreen', edgecolor='white')\n",
    "axes[2].set_title(\"Hauteur des bboxes (normalis√©e)\")\n",
    "axes[2].set_xlabel(\"Hauteur\")\n",
    "axes[2].axvline(np.median(all_heights), color='red', linestyle='--', label=f'm√©diane={np.median(all_heights):.3f}')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Alerte si bboxes tr√®s petites\n",
    "small_threshold = 0.02  # 2% de l'image\n",
    "n_small = sum(1 for w, h in zip(all_widths, all_heights) if w < small_threshold or h < small_threshold)\n",
    "if n_small > 0:\n",
    "    pct = n_small / len(all_widths) * 100\n",
    "    print(f\"\\n‚ö†Ô∏è  {n_small} bboxes ({pct:.1f}%) sont tr√®s petites (<{small_threshold*100}% de l'image).\")\n",
    "    print(f\"   ‚Üí La taille d'entr√©e imgsz=1024 aidera √† les d√©tecter.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Toutes les bboxes ont une taille raisonnable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7b794",
   "metadata": {},
   "source": [
    "## 5. Corriger les labels (BOM + classes incorrectes)\n",
    "\n",
    "Deux probl√®mes courants d√©tect√©s dans les labels :\n",
    "1. **BOM UTF-8** (`\\ufeff`) : caract√®re invisible en d√©but de fichier, ajout√© par certains √©diteurs Windows\n",
    "2. **Classes incorrectes** : certains fichiers utilisent la classe `17` au lieu de `0` ‚Äî on remap tout vers la classe `0` (palmier unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "bom_fixed = 0\n",
    "class_fixed = 0\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    lbl_dir = os.path.join(DATASET_DIR, 'labels', split)\n",
    "    for lbl_file in sorted(glob.glob(os.path.join(lbl_dir, '*.txt'))):\n",
    "        # Lire en binaire pour d√©tecter le BOM\n",
    "        with open(lbl_file, 'rb') as f:\n",
    "            raw = f.read()\n",
    "\n",
    "        # Supprimer le BOM UTF-8 (EF BB BF)\n",
    "        had_bom = raw.startswith(b'\\xef\\xbb\\xbf')\n",
    "        if had_bom:\n",
    "            raw = raw[3:]\n",
    "            bom_fixed += 1\n",
    "\n",
    "        # D√©coder et corriger les classes\n",
    "        text = raw.decode('utf-8')\n",
    "        new_lines = []\n",
    "        file_class_fixed = False\n",
    "        for line in text.strip().split('\\n'):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5 and parts[0] != '0':\n",
    "                parts[0] = '0'  # Remap toute classe vers 0 (palmier)\n",
    "                file_class_fixed = True\n",
    "            new_lines.append(' '.join(parts))\n",
    "\n",
    "        if file_class_fixed:\n",
    "            class_fixed += 1\n",
    "\n",
    "        # R√©√©crire si modifi√©\n",
    "        if had_bom or file_class_fixed:\n",
    "            with open(lbl_file, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "                f.write('\\n'.join(new_lines) + '\\n')\n",
    "\n",
    "# Supprimer les fichiers .cache corrompus\n",
    "for cache_file in glob.glob(os.path.join(DATASET_DIR, 'labels', '*.cache')):\n",
    "    os.remove(cache_file)\n",
    "    print(f\"  Cache supprim√© : {cache_file}\")\n",
    "\n",
    "print(f\"\\n‚úÖ BOM supprim√© de {bom_fixed} fichiers.\")\n",
    "print(f\"‚úÖ Classe corrig√©e (‚Üí 0) dans {class_fixed} fichiers.\")\n",
    "print(\"   Les labels sont maintenant pr√™ts pour YOLO.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14457d96",
   "metadata": {},
   "source": [
    "## 6. Convertir les images RGBA ‚Üí RGB\n",
    "\n",
    "Les GeoTIFF ont 4 canaux (RGBA) mais YOLOv8 attend 3 canaux (RGB). On convertit toutes les images en supprimant le canal alpha, et on les sauvegarde en PNG (format standard pour YOLO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "converted = 0\n",
    "for split in ['train', 'val']:\n",
    "    img_dir = os.path.join(DATASET_DIR, 'images', split)\n",
    "    for img_path in sorted(glob.glob(os.path.join(img_dir, '*.tif'))):\n",
    "        img = Image.open(img_path)\n",
    "        # Convertir en RGB si l'image a un canal alpha (RGBA)\n",
    "        if img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "        elif img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        # Sauvegarder en PNG (m√™me nom, extension .png)\n",
    "        png_path = os.path.splitext(img_path)[0] + '.png'\n",
    "        img.save(png_path)\n",
    "        converted += 1\n",
    "\n",
    "    # Supprimer les anciens .tif pour √©viter les doublons\n",
    "    for tif_path in glob.glob(os.path.join(img_dir, '*.tif')):\n",
    "        os.remove(tif_path)\n",
    "\n",
    "# Supprimer les .cache pour forcer YOLO √† rescanner les nouvelles images\n",
    "for cache_file in glob.glob(os.path.join(DATASET_DIR, 'labels', '*.cache')):\n",
    "    os.remove(cache_file)\n",
    "\n",
    "print(f\"‚úÖ {converted} images converties de RGBA/TIF ‚Üí RGB/PNG.\")\n",
    "print(f\"   Les fichiers .tif originaux ont √©t√© supprim√©s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1c9ee",
   "metadata": {},
   "source": [
    "## 7. Entra√Æner le mod√®le YOLOv8n (adapt√© petit dataset)\n",
    "\n",
    "Avec seulement **38 images d'entra√Ænement**, il faut √©viter l'overfitting. On utilise **YOLOv8n** (nano, 3M params) au lieu de YOLOv8s (11M) et on applique une strat√©gie de **fine-tuning** :\n",
    "\n",
    "**Adaptations au petit dataset :**\n",
    "- `yolov8n.pt` : mod√®le l√©ger ‚Üí moins de risque d'overfitting\n",
    "- `imgsz=640` : proche du natif 680px (pas d'upscale inutile)\n",
    "- `freeze=10` : geler le backbone pr√©-entra√Æn√©, ne fine-tuner que la t√™te de d√©tection\n",
    "- `lr0=0.001` : learning rate bas pour du fine-tuning\n",
    "- `copy_paste=0.3` : copie-colle d'objets entre images (augmentation tr√®s efficace)\n",
    "- `mixup=0.15` : m√©lange d'images pour r√©gulariser\n",
    "- `epochs=200` / `patience=30` : plus de temps avec LR bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50927c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8n (nano) ‚Äî mieux adapt√© √† un petit dataset (38 images)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Entra√Ænement optimis√© pour petit dataset + vue a√©rienne\n",
    "results = model.train(\n",
    "    data=YAML_PATH,\n",
    "    epochs=200,\n",
    "    imgsz=640,           # proche du natif 680px, pas d'upscale\n",
    "    batch=8,\n",
    "    project=os.path.join(DATASET_DIR, 'runs'),\n",
    "    name='palmier_detect',\n",
    "    exist_ok=True,\n",
    "    # --- Fine-tuning ---\n",
    "    freeze=10,           # geler le backbone (couches 0-9), fine-tuner la t√™te\n",
    "    lr0=0.001,           # LR bas pour fine-tuning\n",
    "    lrf=0.01,            # LR final = lr0 * lrf\n",
    "    cos_lr=True,         # cosine annealing\n",
    "    # --- Early stopping ---\n",
    "    patience=30,         # 30 √©poques sans am√©lioration ‚Üí arr√™t\n",
    "    # --- Augmentations vue a√©rienne ---\n",
    "    degrees=90.0,        # rotation ¬±90¬∞ (palmiers vus du dessus)\n",
    "    flipud=0.5,          # retournement vertical (vue z√©nithale)\n",
    "    fliplr=0.5,          # retournement horizontal\n",
    "    scale=0.3,           # multi-scale mod√©r√© (petit dataset)\n",
    "    mosaic=1.0,          # mosaic activ√©\n",
    "    close_mosaic=20,     # d√©sactiver mosaic les 20 derni√®res √©poques\n",
    "    copy_paste=0.3,      # copie-colle d'objets entre images\n",
    "    mixup=0.15,          # m√©lange d'images pour r√©gulariser\n",
    "    # --- Sauvegarde ---\n",
    "    save=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac988d",
   "metadata": {},
   "source": [
    "## 6. Visualiser les r√©sultats d'entra√Ænement\n",
    "\n",
    "Afficher les courbes de loss et les m√©triques de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "run_dir = os.path.join(DATASET_DIR, 'runs', 'palmier_detect')\n",
    "\n",
    "# Afficher les courbes de r√©sultats\n",
    "results_img = os.path.join(run_dir, 'results.png')\n",
    "if os.path.exists(results_img):\n",
    "    display(Image(filename=results_img, width=900))\n",
    "else:\n",
    "    print(\"Fichier results.png non trouv√©.\")\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "conf_img = os.path.join(run_dir, 'confusion_matrix.png')\n",
    "if os.path.exists(conf_img):\n",
    "    display(Image(filename=conf_img, width=600))\n",
    "\n",
    "# Afficher des pr√©dictions sur le set de validation\n",
    "val_img = os.path.join(run_dir, 'val_batch0_pred.png')\n",
    "if os.path.exists(val_img):\n",
    "    display(Image(filename=val_img, width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e875ce0",
   "metadata": {},
   "source": [
    "## 7. √âvaluation d√©taill√©e sur le set de validation\n",
    "\n",
    "On lance une √©valuation formelle avec le meilleur mod√®le pour obtenir les m√©triques pr√©cises (mAP50, mAP50-95, pr√©cision, rappel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c18aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le meilleur mod√®le et lancer la validation\n",
    "run_dir = os.path.join(DATASET_DIR, 'runs', 'palmier_detect')\n",
    "best_model_path = os.path.join(run_dir, 'weights', 'best.pt')\n",
    "\n",
    "val_model = YOLO(best_model_path)\n",
    "metrics = val_model.val(data=YAML_PATH, imgsz=640, split='val')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"M√âTRIQUES DE VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Pr√©cision (P)   : {metrics.box.mp:.4f}\")\n",
    "print(f\"  Rappel (R)      : {metrics.box.mr:.4f}\")\n",
    "print(f\"  mAP@50          : {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95       : {metrics.box.map:.4f}\")\n",
    "print()\n",
    "\n",
    "# Interpr√©tation\n",
    "map50 = metrics.box.map50\n",
    "if map50 >= 0.85:\n",
    "    print(\"‚úÖ Excellent ! Le mod√®le d√©tecte tr√®s bien les palmiers.\")\n",
    "elif map50 >= 0.70:\n",
    "    print(\"üëç Bon r√©sultat. Peut √™tre am√©lior√© avec plus de donn√©es ou plus d'√©poques.\")\n",
    "elif map50 >= 0.50:\n",
    "    print(\"‚ö†Ô∏è  R√©sultat moyen. V√©rifiez la qualit√© des annotations et augmentez les donn√©es.\")\n",
    "else:\n",
    "    print(\"‚ùå R√©sultat faible. Le dataset ou les annotations n√©cessitent une r√©vision.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d01c69",
   "metadata": {},
   "source": [
    "## 8. Exporter le meilleur mod√®le en ONNX\n",
    "\n",
    "On charge le meilleur poids (`best.pt`) et on l'exporte au format ONNX avec `imgsz=640` (m√™me taille que l'entra√Ænement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd201a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le meilleur mod√®le entra√Æn√©\n",
    "best_model_path = os.path.join(run_dir, 'weights', 'best.pt')\n",
    "assert os.path.isfile(best_model_path), f\"Mod√®le introuvable : {best_model_path}\"\n",
    "\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# Exporter en ONNX (opset=17 pour compatibilit√© avec Deepness/QGIS)\n",
    "onnx_path = best_model.export(format='onnx', imgsz=640, opset=17)\n",
    "print(f\"Mod√®le ONNX export√© : {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28a2a3",
   "metadata": {},
   "source": [
    "## 9. Ajouter les m√©tadonn√©es Deepness au fichier ONNX\n",
    "\n",
    "Le plugin **Deepness** pour QGIS attend des m√©tadonn√©es sp√©cifiques dans le mod√®le ONNX.\n",
    "On les ajoute ici directement dans le fichier.\n",
    "\n",
    "**Important** : ajustez la valeur `resolution` (en cm/pixel) selon la r√©solution r√©elle de vos orthophotos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46208d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import json\n",
    "\n",
    "# Charger le mod√®le ONNX\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "\n",
    "# --- Supprimer toutes les m√©tadonn√©es existantes (ajout√©es par Ultralytics) ---\n",
    "# Deepness fait json.loads() sur CHAQUE valeur ‚Üí il faut que tout soit du JSON valide.\n",
    "# Les m√©tadonn√©es Ultralytics ne sont pas au bon format ‚Üí on les supprime.\n",
    "while len(onnx_model.metadata_props) > 0:\n",
    "    onnx_model.metadata_props.pop()\n",
    "\n",
    "# --- M√©tadonn√©es Deepness ---\n",
    "# IMPORTANT : toutes les valeurs doivent √™tre encod√©es avec json.dumps()\n",
    "# car Deepness appelle json.loads() sur chaque valeur lue.\n",
    "# R√©f: https://github.com/PUTvision/qgis-plugin-deepness/blob/devel/tutorials/detection/cars_yolov7/car_detection__prepare_and_train.ipynb\n",
    "\n",
    "class_names = {0: 'palmier'}  # cl√© int ‚Üí json.dumps convertira en \"0\"\n",
    "\n",
    "m1 = onnx_model.metadata_props.add()\n",
    "m1.key = 'model_type'\n",
    "m1.value = json.dumps('Detector')         # ‚Üí '\"Detector\"'\n",
    "\n",
    "m2 = onnx_model.metadata_props.add()\n",
    "m2.key = 'class_names'\n",
    "m2.value = json.dumps(class_names)         # ‚Üí '{\"0\": \"palmier\"}'\n",
    "\n",
    "m3 = onnx_model.metadata_props.add()\n",
    "m3.key = 'resolution'\n",
    "m3.value = json.dumps(30)                  # cm/pixel ‚Äî √† adapter !\n",
    "\n",
    "m4 = onnx_model.metadata_props.add()\n",
    "m4.key = 'det_conf'\n",
    "m4.value = json.dumps(0.3)\n",
    "\n",
    "m5 = onnx_model.metadata_props.add()\n",
    "m5.key = 'det_iou_thresh'\n",
    "m5.value = json.dumps(0.5)\n",
    "\n",
    "m6 = onnx_model.metadata_props.add()\n",
    "m6.key = 'det_type'\n",
    "m6.value = json.dumps('YOLO_Ultralytics')  # ‚Üí '\"YOLO_Ultralytics\"'\n",
    "\n",
    "# Sauvegarder le mod√®le ONNX avec les m√©tadonn√©es\n",
    "output_onnx_path = os.path.join(DATASET_DIR, 'palmier_yolov8n_deepness.onnx')\n",
    "onnx.save(onnx_model, output_onnx_path)\n",
    "\n",
    "print(f\"Mod√®le ONNX final sauvegard√© : {output_onnx_path}\")\n",
    "print(f\"Taille : {os.path.getsize(output_onnx_path) / 1024 / 1024:.1f} Mo\")\n",
    "print()\n",
    "print(\"M√©tadonn√©es Deepness ajout√©es :\")\n",
    "for prop in onnx_model.metadata_props:\n",
    "    print(f\"  {prop.key}: {prop.value}\")\n",
    "    # V√©rification : chaque valeur doit √™tre parsable par json.loads\n",
    "    json.loads(prop.value)\n",
    "print(\"\\n‚úÖ Toutes les valeurs sont du JSON valide.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e36f5f",
   "metadata": {},
   "source": [
    "## 10. V√©rifier les m√©tadonn√©es du mod√®le ONNX\n",
    "\n",
    "On relit le fichier ONNX pour confirmer que les m√©tadonn√©es sont bien enregistr√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification\n",
    "check_model = onnx.load(output_onnx_path)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"M√©tadonn√©es du mod√®le ONNX export√©\")\n",
    "print(\"=\" * 50)\n",
    "for prop in check_model.metadata_props:\n",
    "    print(f\"  {prop.key}: {prop.value}\")\n",
    "print()\n",
    "print(f\"Entr√©es du mod√®le :\")\n",
    "for inp in check_model.graph.input:\n",
    "    shape = [d.dim_value if d.dim_value else d.dim_param for d in inp.type.tensor_type.shape.dim]\n",
    "    print(f\"  {inp.name}: {shape}\")\n",
    "print(f\"Sorties du mod√®le :\")\n",
    "for out in check_model.graph.output:\n",
    "    shape = [d.dim_value if d.dim_value else d.dim_param for d in out.type.tensor_type.shape.dim]\n",
    "    print(f\"  {out.name}: {shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be85d05",
   "metadata": {},
   "source": [
    "## 11. T√©l√©charger le mod√®le (optionnel)\n",
    "\n",
    "Le mod√®le est d√©j√† sauvegard√© dans Google Drive √† l'emplacement :\n",
    "\n",
    "```\n",
    "Google Drive/Recherche/dataset_palmiers/palmier_yolov8n_deepness.onnx\n",
    "```\n",
    "\n",
    "Vous pouvez aussi le t√©l√©charger directement depuis Colab :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d637da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# D√©commenter la ligne suivante pour t√©l√©charger le mod√®le\n",
    "# files.download(output_onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4be9e",
   "metadata": {},
   "source": [
    "## Utilisation dans QGIS avec Deepness\n",
    "\n",
    "1. Ouvrez QGIS et installez le plugin **Deepness** depuis le gestionnaire d'extensions\n",
    "2. Chargez votre orthophoto dans QGIS\n",
    "3. Lancez Deepness : **Plugins > Deepness > Detection**\n",
    "4. S√©lectionnez le fichier `palmier_yolov8n_deepness.onnx`\n",
    "5. Les param√®tres (confiance, IoU, r√©solution) seront automatiquement lus depuis les m√©tadonn√©es\n",
    "6. Lancez l'inf√©rence ‚Äî les palmiers d√©tect√©s appara√Ætront comme une couche vectorielle"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
